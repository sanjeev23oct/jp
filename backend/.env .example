# Server Configuration
PORT=3001
NODE_ENV=development

# LLM Configuration
LLM_PROVIDER=
LLM_API_KEY=s
LLM_MODEL=
LLM_BASE_URL=
LLM_DEFAULT_TEMPERATURE=0.7
LLM_DEFAULT_MAX_TOKENS=8000

# Alternative LLM Providers (uncomment to use)
# OpenAI
# LLM_PROVIDER=openai
# LLM_API_KEY=sk-...
# LLM_MODEL=gpt-4-turbo-preview
# LLM_BASE_URL=https://api.openai.com/v1

# Anthropic
# LLM_PROVIDER=anthropic
# LLM_API_KEY=sk-ant-...
# LLM_MODEL=claude-3-sonnet-20240229
# LLM_BASE_URL=https://api.anthropic.com

# Ollama (local)
# LLM_PROVIDER=ollama
# LLM_MODEL=llama2
# LLM_BASE_URL=http://localhost:11434

# CORS
CORS_ORIGIN=http://localhost:5189

# Rate Limiting
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# Logging
LOG_LEVEL=info

# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=jp
DB_USER=
DB_PASSWORD=

